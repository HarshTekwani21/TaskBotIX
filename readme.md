# Multi-Agent System with LLM Groq and Ollama

## Overview
This project enables users to create and manage AI agents powered by LLM Groq and Ollama, utilizing user-provided documents. Built with FastAPI for the backend and Uvicorn as the ASGI server, this system allows for high-performance API interactions.

## Features
- **Multi-User Authentication**: Secure access for multiple users to create and manage their agents.
- **Agent Creation**: Users can customize multiple AI agents tailored to specific tasks.
- **Document-Based Responses**: Agents leverage the content of user-uploaded documents to provide relevant answers.
- **User-Friendly Interface**: The application features an intuitive HTML frontend for easy interaction with the agents.

## Technologies
- **FastAPI**: A modern web framework for building APIs quickly and efficiently.
- **Uvicorn**: An ASGI server that runs FastAPI applications.
- **HTML/CSS**: For creating the frontend interface that allows users to interact with the system.

## Key Dependencies
- **langchain**: Framework for building language model applications.
- **sqlalchemy**: ORM for database interactions.
- **pydantic**: Data validation and settings management using Python type annotations.
- **python-dotenv**: For loading environment variables from a `.env` file.

This project combines cutting-edge AI technology with a straightforward user interface, making it easy for users to deploy and interact with their AI agents.
![image](https://github.com/user-attachments/assets/abe8b4ae-9228-4e7d-a320-2d833fcf6558)
![image](https://github.com/user-attachments/assets/a73ce288-ef16-480e-a999-b6e123c405b9)
![image](https://github.com/user-attachments/assets/53cc6065-064e-47a3-94d3-86b5dd7e1663)
